{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 20:40:35.745061: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/azzanf/Documents/Azza/TA/Code/.conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/Users/azzanf/Documents/Azza/TA/Code/.conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['dlopen(/Users/azzanf/Documents/Azza/TA/Code/.conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so, 0x0006): symbol not found in flat namespace (__ZN3tsl2io7DirnameENSt3__117basic_string_viewIcNS1_11char_traitsIcEEEE)']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/Users/azzanf/Documents/Azza/TA/Code/.conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/Users/azzanf/Documents/Azza/TA/Code/.conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['dlopen(/Users/azzanf/Documents/Azza/TA/Code/.conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so, 0x0006): symbol not found in flat namespace (__ZN10tensorflow11TensorProtoC1EPN6google8protobuf5ArenaEb)']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(df):\n",
    "    image_data = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        image_path = row['filepath']\n",
    "        category = row['Category']\n",
    "        image = tf.keras.preprocessing.image.load_img(image_path, target_size=(64, 64), color_mode='grayscale')\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        image_data.append(image)\n",
    "\n",
    "    image_data = np.array(image_data)\n",
    "    image_data = image_data.astype('float32') / 255.0\n",
    "    \n",
    "    return image_data\n",
    "\n",
    "def load_augmented_images(df, batch_size=32):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1.0/255.0,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1, \n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    image_data = []\n",
    "    label_data = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        image_path = row['filepath']\n",
    "        category = row['Category']\n",
    "        image = tf.keras.preprocessing.image.load_img(image_path, target_size=(64, 64), color_mode='grayscale')\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        \n",
    "        # Apply data augmentation individually to each image\n",
    "        augmented_images = datagen.flow(np.expand_dims(image, axis=0), batch_size=batch_size, shuffle=False)\n",
    "        for _ in range(batch_size):\n",
    "            augmented_image = augmented_images.next()\n",
    "            image_data.append(augmented_image[0])\n",
    "            label_data.append(category)\n",
    "    \n",
    "    # Convert the lists to numpy arrays\n",
    "    image_data = np.array(image_data)\n",
    "    label_data = np.array(label_data)\n",
    "    \n",
    "    return image_data, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train_data.csv\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "val_df = pd.read_csv('val_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_classes = [\"Drowsy\", \"Neutral\"]\n",
    "num_classes = len(name_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_augmented_images(train_df)\n",
    "val_images, val_labels = load_augmented_images(val_df)\n",
    "test_images = load_images(test_df)\n",
    "\n",
    "train_labels = label_encoder.transform(train_labels)\n",
    "val_labels = label_encoder.transform(val_labels)\n",
    "test_labels = label_encoder.transform(test_df['Category'])\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
    "val_labels = tf.keras.utils.to_categorical(val_labels, num_classes)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "def create_cnn_model(num_classes):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # First set of Convolutional, BatchNormalization, and ReLU layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    # Second set of Convolutional, BatchNormalization, and ReLU layers\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    # Third set of Convolutional, BatchNormalization, and ReLU layers\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    # Flatten the output to prepare for dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    # Output layer with units corresponding to the number of classes\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cnn_model(num_classes)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', np.unique(train_labels.argmax(axis=1)), train_labels.argmax(axis=1))\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "244/244 [==============================] - 8s 28ms/step - loss: 0.4778 - accuracy: 0.8127 - val_loss: 0.7793 - val_accuracy: 0.4988\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0701 - accuracy: 0.9748 - val_loss: 0.2472 - val_accuracy: 0.8859\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.1159 - val_accuracy: 0.9530\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0789 - val_accuracy: 0.9754\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.2921 - val_accuracy: 0.8744\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.0149 - val_accuracy: 0.9964\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.1337 - val_accuracy: 0.9648\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0329 - val_accuracy: 0.9851\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 7s 28ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.3022 - val_accuracy: 0.9275\n",
      "Epoch 9: early stopping\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5079 - accuracy: 0.9720\n",
      "Test accuracy: 0.9719626307487488\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=100, batch_size=64, validation_data=(val_images, val_labels), callbacks=[early_stop], class_weight=class_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_ijn0xb6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_ijn0xb6/assets\n",
      "2023-07-26 10:57:56.914525: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-07-26 10:57:56.914566: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "# Convert the Keras model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# # Save the TensorFlow Lite model to a file\n",
    "# with open('model_cnn.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
